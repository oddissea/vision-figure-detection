{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e104d9a-6766-4ef2-85fa-a2a42a4c4b8a",
   "metadata": {},
   "source": [
    "# Notebook 2: Clasificación de la orientación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fefffa1-1825-4903-b22d-a4922659d8ce",
   "metadata": {},
   "source": [
    "## 1. Estrategia para resolver la tarea:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f59494-2bd9-48ad-916b-2a7fcf0f19ab",
   "metadata": {},
   "source": [
    "Nuestro objetivo ahora es crear claramente una red neuronal capaz de **clasificar las imágenes según su orientación en cuatro categorías: {0°, 90°, 180°, -90°}**.\n",
    "\n",
    "- **Entrada**: imágenes ROI (preferentemente ya recortadas a partir de la tarea anterior), posiblemente tamaño reducido (por ejemplo, 128x128 píxeles).\n",
    "- **Salida**: Una clase correspondiente a la orientación del ROI (0º, 90º, 180º, -90º)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f553588e-3d6a-41a1-b5c9-dcfb0ade2a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca245c87-c99a-4ad9-b9c9-e644ceb04646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def establecer_semilla(semilla=42):\n",
    "    random.seed(semilla)\n",
    "    np.random.seed(semilla)\n",
    "    torch.manual_seed(semilla)\n",
    "    torch.cuda.manual_seed_all(semilla)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Establecemos la semilla\n",
    "establecer_semilla(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ca0ecd-3c45-4bd9-872c-e5998eb10f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dispositivo (GPU si disponible)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad0b83-60db-469d-a7e0-db590b3f9c96",
   "metadata": {},
   "source": [
    "## 2. Preparación del Dataset para clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625f68d1-0d2b-4013-ad23-ae0684502ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrientacionROIDataset(Dataset):\n",
    "    def __init__(self, df_trazas, path_roi, image_size=(128,128)):\n",
    "        self.df_trazas = df_trazas.reset_index(drop=True)\n",
    "        self.path_roi = path_roi\n",
    "        self.image_size = image_size\n",
    "        self.label_dict = {'0':0, '90':1, '180':2, '-90':3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_trazas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        registro = self.df_trazas.iloc[idx]\n",
    "        ruta_img_roi = os.path.join(self.path_roi, registro['fname'])\n",
    "\n",
    "        img_roi = cv2.imread(ruta_img_roi, cv2.IMREAD_GRAYSCALE)\n",
    "        img_roi = cv2.resize(img_roi, self.image_size) / 255.0\n",
    "        img_roi = np.expand_dims(img_roi, axis=0)\n",
    "\n",
    "        # Conversión adecuada de float a string entero\n",
    "        etiqueta_orientacion = self.label_dict[str(int(float(registro['rot'])))]\n",
    "\n",
    "        return torch.tensor(img_roi, dtype=torch.float32), etiqueta_orientacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f9abc5-e8e4-49e0-a757-5da1452e43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trazas_limpio = pd.read_csv(\"df_trazas_limpio.csv\")\n",
    "df_trazas_limpio = df_trazas_limpio.dropna(subset=[\"rot\"]).copy()\n",
    "\n",
    "# Separación: primero train + (val + test)\n",
    "df_train, df_temp = train_test_split(\n",
    "    df_trazas_limpio,\n",
    "    test_size=0.3,\n",
    "    stratify=df_trazas_limpio[\"rot\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ahora val y test (15% cada uno)\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=df_temp[\"rot\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6555d62-58c7-4442-8878-efb97e3c1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas y tamaño\n",
    "path_roi = \"REY_DATASET/REY_roi_rot0\"\n",
    "image_size = (128, 128)\n",
    "batch_size = 16\n",
    "\n",
    "# Datasets\n",
    "train_dataset = OrientacionROIDataset(df_train, path_roi, image_size)\n",
    "val_dataset   = OrientacionROIDataset(df_val, path_roi, image_size)\n",
    "test_dataset  = OrientacionROIDataset(df_test, path_roi, image_size)\n",
    "\n",
    "# Dataloaders\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "loader_val   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "loader_test  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bcf4c6-2c26-4c46-8a25-73a36273096f",
   "metadata": {},
   "source": [
    "## 3. Modelo CNN adaptado a clasificación usando ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77312c1a-1996-4347-8f03-a8582a3cee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet18 preentrenada\n",
    "resnet_clasif = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# Ajustamos última capa para clasificación en 4 clases\n",
    "resnet18.fc = nn.Sequential(\n",
    "    nn.Linear(resnet_clasif.fc.in_features, 128), nn.ReLU(),\n",
    "    nn.Linear(128, 4)\n",
    ")\n",
    "\n",
    "# Modelo al dispositivo\n",
    "resnet_clasif = resnet_clasif.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08775f6-afec-4190-842a-09f79d8d0eae",
   "metadata": {},
   "source": [
    "## 4. Pérdida, optimizador y entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d7e03d-865e-49fe-a300-dffbce665522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/20] - Pérdida train: 2.721372 | val: 0.764039\n",
      "Época [2/20] - Pérdida train: 0.202030 | val: 0.331167\n",
      "Época [3/20] - Pérdida train: 0.045853 | val: 0.288785\n",
      "Época [4/20] - Pérdida train: 0.019051 | val: 0.394857\n",
      "Época [5/20] - Pérdida train: 0.019278 | val: 0.512999\n",
      "Época [6/20] - Pérdida train: 0.012110 | val: 0.433982\n",
      "Época [7/20] - Pérdida train: 0.007385 | val: 0.497065\n",
      "Época [8/20] - Pérdida train: 0.004294 | val: 0.379149\n",
      "Época [9/20] - Pérdida train: 0.021696 | val: 0.599762\n",
      "Época [10/20] - Pérdida train: 0.024760 | val: 0.646185\n",
      "Época [11/20] - Pérdida train: 0.012472 | val: 0.743102\n",
      "Época [12/20] - Pérdida train: 0.005018 | val: 0.637637\n",
      "Época [13/20] - Pérdida train: 0.007792 | val: 0.592858\n",
      "Época [14/20] - Pérdida train: 0.016153 | val: 0.495021\n",
      "Época [15/20] - Pérdida train: 0.025603 | val: 0.867058\n",
      "Época [16/20] - Pérdida train: 0.022496 | val: 0.482715\n",
      "Época [17/20] - Pérdida train: 0.023989 | val: 0.407945\n",
      "Época [18/20] - Pérdida train: 0.016761 | val: 0.524939\n",
      "Época [19/20] - Pérdida train: 0.009200 | val: 0.521782\n",
      "Época [20/20] - Pérdida train: 0.002239 | val: 0.533091\n"
     ]
    }
   ],
   "source": [
    "criterio_clasificacion = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.Adam(resnet_clasif.parameters(), lr=1e-4)\n",
    "\n",
    "num_epocas = 20\n",
    "\n",
    "for epoca in range(num_epocas):\n",
    "    resnet_clasif.train()\n",
    "    perdida_epoca_train = 0.0\n",
    "\n",
    "    for imgs, labels in loader_train:\n",
    "        imgs = imgs.repeat(1, 3, 1, 1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizador.zero_grad()\n",
    "        logits = resnet_clasif(imgs)\n",
    "        perdida = criterio_clasificacion(logits, labels)\n",
    "        perdida.backward()\n",
    "        optimizador.step()\n",
    "\n",
    "        perdida_epoca_train += perdida.item()\n",
    "\n",
    "    perdida_media_train = perdida_epoca_train / len(loader_train)\n",
    "\n",
    "    # Validación\n",
    "    resnet_clasif.eval()\n",
    "    perdida_epoca_val = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader_val:\n",
    "            imgs = imgs.repeat(1, 3, 1, 1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = resnet_clasif(imgs)\n",
    "            perdida = criterio_clasificacion(logits, labels)\n",
    "            perdida_epoca_val += perdida.item()\n",
    "\n",
    "    perdida_media_val = perdida_epoca_val / len(loader_val)\n",
    "\n",
    "    print(f\"Época [{epoca+1}/{num_epocas}] - Pérdida train: {perdida_media_train:.6f} | val: {perdida_media_val:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f41f41c-7b25-4aea-93d3-c17e3fe2693a",
   "metadata": {},
   "source": [
    "## 5. Evaluación detallada (Accuracy y Matriz de confusión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732b31ec-8d16-45c6-827d-ccce4b67d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy global (test): 0.9624\n",
      "Matriz de confusión (test):\n",
      " [[45  1  0  1]\n",
      " [ 0 65  1  0]\n",
      " [ 1  0  3  0]\n",
      " [ 1  0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "resnet_clasif.eval()\n",
    "predicciones, reales = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in loader_test:\n",
    "        imgs = imgs.repeat(1, 3, 1, 1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = resnet_clasif(imgs)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        predicciones.extend(preds)\n",
    "        reales.extend(labels.cpu().numpy())\n",
    "\n",
    "# Precisión global\n",
    "precision = accuracy_score(reales, predicciones)\n",
    "print(f\"Accuracy global (test): {precision:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "matriz_confusion = confusion_matrix(reales, predicciones)\n",
    "print(\"Matriz de confusión (test):\\n\", matriz_confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37feb257-0cc2-45d5-a334-5c876f69ff4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_clasif.state_dict(), \"modelo_orientacion_resnet18.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed01309-30d8-4d91-a741-06df31d880cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
